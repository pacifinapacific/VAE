{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875\n",
      "313\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import os\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "from torchvision.utils import save_image\n",
    "%matplotlib inline\n",
    "cuda = torch.cuda.is_available()\n",
    "if cuda:\n",
    "    print('cuda is available!')\n",
    "\n",
    "if not os.path.exists(\"save_image\"):\n",
    "    os.mkdir(\"save_image\")\n",
    "if not os.path.exists(\"dataset\"):\n",
    "    os.mkdir(\"dataset\")\n",
    "if not os.path.exists(\"asset\"):\n",
    "    os.mkdir(\"asset\")\n",
    "\n",
    "\n",
    "mnist_train=MNIST(\"dataset\",train=True,download=True, transform=transforms.ToTensor())\n",
    "mnist_test=MNIST(\"dataset\",train=False,download=True, transform=transforms.ToTensor())\n",
    "train_loader=DataLoader(mnist_train,batch_size=32,shuffle=True)\n",
    "test_loader=DataLoader(mnist_test,batch_size=32,shuffle=False)\n",
    "\n",
    "\n",
    "print(len(train_loader)) #60000/batch_size\n",
    "print(len(test_loader)) #10000/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Label=1')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11799c048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_iter=iter(train_loader)\n",
    "images,labels=data_iter.next()\n",
    "image=images[0].numpy() #(1,28,28)\n",
    "image=image.reshape(28,28)\n",
    "plt.imshow(image,cmap=\"gray\")\n",
    "plt.title(\"Label={}\".format(labels[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,input_channels,hidden_size):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.input_channels=input_channels\n",
    "        self.hidden_size=hidden_size\n",
    "        #(1,28,28)\n",
    "        self.encode=nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(self.input_channels,16,kernel_size=3,stride=2,padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            #(16,14,14)\n",
    "\n",
    "            nn.Conv2d(16,32,kernel_size=3,stride=2,padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            #(32,7,7)\n",
    "\n",
    "            nn.Conv2d(32,64,kernel_size=2,stride=2,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())\n",
    "            #(64,4,4)\n",
    "        \n",
    "        self.mean=nn.Sequential(\n",
    "            nn.Linear(64*4*4,1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024,hidden_size))       \n",
    "        self.logvar=nn.Sequential(\n",
    "            nn.Linear(64*4*4,1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024,hidden_size))\n",
    "            \n",
    "    def forward(self,x):\n",
    "        batch_size=x.size()[0]\n",
    "        encoding=self.encode(x)\n",
    "        mean=self.mean(encoding.view(batch_size,-1))\n",
    "        logvar=self.logvar(encoding.view(batch_size,-1))\n",
    "        \n",
    "        return mean,logvar\n",
    "    \n",
    "    def encode_layer(self,x):\n",
    "        batch_size=x.size()[0]\n",
    "        output=self.encode(x)\n",
    "        \n",
    "        return output\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 32]) torch.Size([32, 32])\n"
     ]
    }
   ],
   "source": [
    "test_input=torch.ones(32,1,28,28)\n",
    "encoder=Encoder(1,32)\n",
    "\n",
    "m,v=encoder(test_input)\n",
    "\n",
    "print(m.size(),v.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,hidden_size):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.hidden_size=hidden_size\n",
    "        \n",
    "        self.pre=nn.Sequential(\n",
    "            nn.Linear(hidden_size,64*4*4),\n",
    "            nn.BatchNorm1d(64*4*4),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.decode=nn.Sequential(\n",
    "            #(64,4,4)\n",
    "            nn.ConvTranspose2d(64,32,kernel_size=3,stride=2,padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            #(32,7,7)\n",
    "            \n",
    "            nn.ConvTranspose2d(32,16,kernel_size=4,stride=2,padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            #(16,14,14)\n",
    "            \n",
    "            nn.ConvTranspose2d(16,8,kernel_size=4,stride=2,padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            #(8,28,28),\n",
    "            \n",
    "            nn.ConvTranspose2d(8,1,kernel_size=3,stride=1,padding=1),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "    def forward(self,code):\n",
    "        preprocess=self.pre(code)\n",
    "        preprocess=preprocess.view(-1,64,4,4)\n",
    "            \n",
    "        out=self.decode(preprocess)\n",
    "        return out\n",
    "            \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 28, 28])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1=torch.ones(32,32)\n",
    "\n",
    "\n",
    "decoder=Decoder(32)\n",
    "out=decoder(test1)        \n",
    "out.size()     \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self,input_channels,hidden_size):\n",
    "        super(VAE,self).__init__()\n",
    "        self.input_channles=input_channels\n",
    "        self.hidden_size=hidden_size\n",
    "        self.encoder=Encoder(input_channels,hidden_size)\n",
    "        self.decoder=Decoder(hidden_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        batch_size=x.size()[0]\n",
    "        mean,logvar=self.encoder(x)\n",
    "        std=logvar.mul(0.5).exp_()\n",
    "        \n",
    "        noise=torch.randn((batch_size,self.hidden_size))\n",
    "        if cuda:\n",
    "            noise=noise.cuda()\n",
    "        noise=mean+std*noise\n",
    "            \n",
    "        decode_image=self.decoder(noise)\n",
    "        decode_image=decode_image.view(-1,784)\n",
    "        \n",
    "        return mean,logvar,decode_image\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 784])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input=torch.ones(32,1,28,28)\n",
    "if cuda:\n",
    "    test_input=test_input.cuda()\n",
    "vae=VAE(1,32)\n",
    "\n",
    "mean,logvar,image=vae(test_input)\n",
    "\n",
    "image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(input_image,decode_image,mean,logvar):\n",
    "    reconstruction_loss=F.binary_cross_entropy(decode_image,input_image.view(-1,784),size_average=False)\n",
    "    kld_loss=-0.5*torch.sum(1+logvar-mean.pow(2)-logvar.exp())\n",
    "    \n",
    "    loss=reconstruction_loss+kld_loss\n",
    "    \n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=VAE(1,32)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "optimizer=optim.Adam(model.parameters(),lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasakianmin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-cb314941652a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-cb314941652a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecode_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvae_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecode_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss=0\n",
    "    for batch_idx,(data, _) in enumerate(train_loader):\n",
    "        if cuda:\n",
    "            data=V(data.cuda())\n",
    "        else:\n",
    "            data=V(data)\n",
    "        optimizer.zero_grad()\n",
    "        mean,logvar,decode_image=model(data)\n",
    "        loss=vae_loss(data,decode_image,mean,logvar)\n",
    "        loss.backward()\n",
    "        train_loss+=loss.data[0]\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss/=len(train_loader.dataset)\n",
    "    \n",
    "    return train_loss\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss=0\n",
    "    for batch_idx,(data, _) in enumerate(test_loader):\n",
    "        if cuda:\n",
    "            data=V(data.cuda(),valatile=True)\n",
    "        else:\n",
    "            data=V(data,volatile=True)\n",
    "        mean,logvar,decode_image=model(data)\n",
    "        loss=vae_loss(data,decode_image,mean,logvar)\n",
    "        test_loss+=loss.data[0]\n",
    "        \n",
    "        if epoch%10==0:\n",
    "            if batch_idx==0:\n",
    "                n=8\n",
    "                comparison=torch.cat([data[:n],decode_image.view(32,1,28,28)[:n]])\n",
    "                \n",
    "                save_image(comparison.data.cpu(),\n",
    "                          \"save_image/vae_image{}.png\".format(epoch),nrow=n)\n",
    "    test_loss/=len(test_loader.dataset)\n",
    "    \n",
    "    return test_loss\n",
    "\n",
    "loss_list = []\n",
    "test_loss_list = []\n",
    "num_epochs=100\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    loss = train(epoch)\n",
    "    test_loss = test(epoch)\n",
    "\n",
    "    print('epoch [{}/{}], loss: {:.4f} test_loss: {:.4f}'.format(\n",
    "        epoch + 1,\n",
    "        num_epochs,\n",
    "        loss,\n",
    "        test_loss))\n",
    "\n",
    "    # logging\n",
    "    loss_list.append(loss)\n",
    "    test_loss_list.append(test_loss)\n",
    "\n",
    "# save the training model\n",
    "np.save('asset/loss_list.npy', np.array(loss_list))\n",
    "np.save('asset/test_loss_list.npy', np.array(test_loss_list))\n",
    "torch.save(model.state_dict(), 'assert/vae.pth')\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
